{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "from typing import Self\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from flax import nnx\n",
    "from flax_trainer.loss_fn import mean_squared_error\n",
    "from flax_trainer.trainer import Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from flax_recsys.model.MF import MF\n",
    "\n",
    "sys.path.append(\"/workspace\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000_209, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>1192</td><td>5</td></tr><tr><td>0</td><td>660</td><td>3</td></tr><tr><td>0</td><td>913</td><td>3</td></tr><tr><td>0</td><td>3407</td><td>4</td></tr><tr><td>0</td><td>2354</td><td>5</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6039</td><td>1090</td><td>1</td></tr><tr><td>6039</td><td>1093</td><td>5</td></tr><tr><td>6039</td><td>561</td><td>5</td></tr><tr><td>6039</td><td>1095</td><td>4</td></tr><tr><td>6039</td><td>1096</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000_209, 3)\n",
       "┌─────────┬─────────┬────────┐\n",
       "│ user_id ┆ item_id ┆ rating │\n",
       "│ ---     ┆ ---     ┆ ---    │\n",
       "│ i64     ┆ i64     ┆ i64    │\n",
       "╞═════════╪═════════╪════════╡\n",
       "│ 0       ┆ 1192    ┆ 5      │\n",
       "│ 0       ┆ 660     ┆ 3      │\n",
       "│ 0       ┆ 913     ┆ 3      │\n",
       "│ 0       ┆ 3407    ┆ 4      │\n",
       "│ 0       ┆ 2354    ┆ 5      │\n",
       "│ …       ┆ …       ┆ …      │\n",
       "│ 6039    ┆ 1090    ┆ 1      │\n",
       "│ 6039    ┆ 1093    ┆ 5      │\n",
       "│ 6039    ┆ 561     ┆ 5      │\n",
       "│ 6039    ┆ 1095    ┆ 4      │\n",
       "│ 6039    ┆ 1096    ┆ 4      │\n",
       "└─────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pl.from_pandas(\n",
    "    pd.read_csv(\n",
    "        \"../../dataset/ML1M/ml-1m/ratings.dat\",\n",
    "        delimiter=\"::\",\n",
    "        engine=\"python\",\n",
    "        header=None,\n",
    "        names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_df = rating_df.select(\n",
    "    pl.col(\"user_id\") - pl.col(\"user_id\").min(),\n",
    "    pl.col(\"item_id\") - pl.col(\"item_id\").min(),\n",
    "    \"rating\",\n",
    ")\n",
    "user_num, item_num = (\n",
    "    dataset_df.get_column(\"user_id\").max() + 1,\n",
    "    dataset_df.get_column(\"item_id\").max() + 1,\n",
    ")\n",
    "train_df, valid_df = train_test_split(\n",
    "    dataset_df, test_size=0.1, random_state=0, shuffle=True\n",
    ")\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchLoader:\n",
    "    def __init__(self, df_DATA: pl.DataFrame, batch_size: int, seed: int):\n",
    "        self.df_DATA = df_DATA\n",
    "        self.batch_size = batch_size\n",
    "        self.rngs = nnx.Rngs(0)\n",
    "\n",
    "    def __iter__(self) -> Self:\n",
    "        \"\"\"Prepares for batch iteration\"\"\"\n",
    "\n",
    "        # Num. of data\n",
    "        self.data_size = self.df_DATA.height\n",
    "\n",
    "        # Num. of batch\n",
    "        self.batch_num = math.ceil(self.data_size / self.batch_size)\n",
    "\n",
    "        # Shuffle rows of data\n",
    "        self.shuffled_indices = jax.random.permutation(self.rngs(), self.data_size)\n",
    "        self.X_df, self.y_df = (\n",
    "            self.df_DATA[self.shuffled_indices.tolist(), :].select(\n",
    "                \"user_id\", \"item_id\"\n",
    "            ),\n",
    "            self.df_DATA[self.shuffled_indices.tolist(), :].select(\"rating\"),\n",
    "        )\n",
    "\n",
    "        # Initialize batch index\n",
    "        self.batch_index = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of batches\n",
    "\n",
    "        Returns:\n",
    "            int: The number of batches\n",
    "        \"\"\"\n",
    "\n",
    "        return self.batch_num\n",
    "\n",
    "    def __next__(self) -> tuple[jax.Array, jax.Array]:\n",
    "        \"\"\"Returns data from the current batch\n",
    "\n",
    "        Returns:\n",
    "            jax.Array: The input data.\n",
    "            jax.Array: The target data.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.batch_index >= self.batch_num:\n",
    "            raise StopIteration()\n",
    "\n",
    "        else:\n",
    "            # Extract the {batch_index}-th mini-batch\n",
    "            start_index = self.batch_size * self.batch_index\n",
    "            slice_size = min(self.batch_size, (self.data_size - start_index))\n",
    "            X, y = (\n",
    "                jax.device_put(\n",
    "                    self.X_df[start_index : (start_index + slice_size)].to_numpy()\n",
    "                ),\n",
    "                jax.device_put(\n",
    "                    self.y_df[start_index : (start_index + slice_size)].to_numpy()\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # Update batch index\n",
    "            self.batch_index += 1\n",
    "\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax_trainer.evaluator import BaseEvaluator\n",
    "\n",
    "\n",
    "class Evaluator(BaseEvaluator):\n",
    "    def __init__(self, df_DATA: pl.DataFrame, batch_size: int):\n",
    "        self.df_DATA = df_DATA\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def evaluate(self, model: nnx.Module) -> tuple[float, dict[str, float]]:\n",
    "        pred_y, true_y = [], []\n",
    "\n",
    "        X, true_y = (\n",
    "            jax.device_put(self.df_DATA.select(\"user_id\", \"item_id\").to_numpy()),\n",
    "            jax.device_put(self.df_DATA.select(\"rating\").to_numpy()),\n",
    "        )\n",
    "        pred_y = nnx.jit(model)(X)\n",
    "\n",
    "        mse = jnp.mean((pred_y - true_y) ** 2)\n",
    "        rmse = float(jnp.sqrt(mse))\n",
    "\n",
    "        return rmse, {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  000] loss=3.7516701221466064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 001]: 100%|██████████| 1759/1759 [00:05<00:00, 296.14it/s, batch_loss=3.4941676] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  001] loss=1.843126654624939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 002]: 100%|██████████| 1759/1759 [00:05<00:00, 325.82it/s, batch_loss=1.0742438] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  002] loss=0.9685046076774597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 003]: 100%|██████████| 1759/1759 [00:05<00:00, 324.97it/s, batch_loss=0.66448736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  003] loss=0.9224202036857605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 004]: 100%|██████████| 1759/1759 [00:05<00:00, 319.29it/s, batch_loss=0.6056271] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  004] loss=0.9040776491165161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 005]: 100%|██████████| 1759/1759 [00:05<00:00, 312.86it/s, batch_loss=0.6473345] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  005] loss=0.8928287625312805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 006]: 100%|██████████| 1759/1759 [00:05<00:00, 316.75it/s, batch_loss=0.5314449] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  006] loss=0.8860964179039001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 007]: 100%|██████████| 1759/1759 [00:05<00:00, 318.95it/s, batch_loss=0.5306775] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  007] loss=0.8851304650306702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 008]: 100%|██████████| 1759/1759 [00:06<00:00, 281.81it/s, batch_loss=0.8056063] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  008] loss=0.8868416547775269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 009]: 100%|██████████| 1759/1759 [00:06<00:00, 279.02it/s, batch_loss=0.46339297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  009] loss=0.8906249403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 010]: 100%|██████████| 1759/1759 [00:05<00:00, 311.85it/s, batch_loss=0.5903769] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  010] loss=0.8968890309333801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 011]: 100%|██████████| 1759/1759 [00:05<00:00, 314.84it/s, batch_loss=0.6538729] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  011] loss=0.9015406370162964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 012]: 100%|██████████| 1759/1759 [00:05<00:00, 315.65it/s, batch_loss=0.47154295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  012] loss=0.9077015519142151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 013]: 100%|██████████| 1759/1759 [00:04<00:00, 356.87it/s, batch_loss=0.53116924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  013] loss=0.9140112996101379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 014]: 100%|██████████| 1759/1759 [00:04<00:00, 380.02it/s, batch_loss=0.48564133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  014] loss=0.9191444516181946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 015]: 100%|██████████| 1759/1759 [00:04<00:00, 376.56it/s, batch_loss=0.33390576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  015] loss=0.9264206886291504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 016]: 100%|██████████| 1759/1759 [00:04<00:00, 393.13it/s, batch_loss=0.55270416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  016] loss=0.9326691627502441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TRAIN 017]: 100%|██████████| 1759/1759 [00:05<00:00, 318.77it/s, batch_loss=0.38127318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST  017] loss=0.9374197125434875\n"
     ]
    }
   ],
   "source": [
    "model = MF(user_num=user_num, item_num=item_num, embed_dim=50, rngs=nnx.Rngs(0))\n",
    "loader = MiniBatchLoader(df_DATA=train_df, batch_size=512, seed=0)\n",
    "evaluator = Evaluator(valid_df, batch_size=512)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optax.adamw(learning_rate=0.001, weight_decay=0.001),\n",
    "    train_loader=loader,\n",
    "    loss_fn=mean_squared_error,\n",
    "    test_evaluator=evaluator,\n",
    "    early_stopping_patience=10,\n",
    "    epoch_num=64,\n",
    ")\n",
    "trainer = trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flax-recsys-xS3fZVNL-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
